{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a3234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade huggingface_hub datasets pillow albumentations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a2a27c-33f6-4bc4-9053-e7b6ebb2474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import tensorflow as tf\n",
    "import albumentations\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(\"***\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout, BatchNormalization, MaxPooling2D, Softmax\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress all FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Suppress all UserWarnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acf890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117d3d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"marmal88/skin_cancer\", split=\"train\")\n",
    "valid_dataset = load_dataset(\"marmal88/skin_cancer\", split=\"validation\")\n",
    "test_dataset  = load_dataset(\"marmal88/skin_cancer\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefda44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_to_num = {\n",
    "    \"melanocytic_Nevi\":0,\n",
    "    \"melanoma\":1,\n",
    "    \"benign_keratosis-like_lesions\":2,\n",
    "    \"basal_cell_carcinoma\":3,\n",
    "    \"actinic_keratoses\":4,\n",
    "    \"vascular_lesions\":5,\n",
    "    \"dermatofibroma\":6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dc49f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = albumentations.Compose([albumentations.Resize(width=128, height=128)])\n",
    "def transforms(examples):\n",
    "    examples[\"pixel_values\"] = [(transform(image=np.array(image))[\"image\"] / 255.0) for image in examples[\"image\"]]\n",
    "    examples[\"labels\"] = [dx_to_num[dx] for dx in examples[\"dx\"]]\n",
    "    return examples\n",
    "\n",
    "train_dataset.set_transform(transforms)\n",
    "valid_dataset.set_transform(transforms)\n",
    "test_dataset.set_transform(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f30fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_dataset.to_tf_dataset(columns=[\"pixel_values\"], label_cols=[\"labels\"], shuffle=True, batch_size=32)\n",
    "valid_ds = valid_dataset.to_tf_dataset(columns=[\"pixel_values\"], label_cols=[\"labels\"], shuffle=True, batch_size=32)\n",
    "test_ds = test_dataset.to_tf_dataset(columns=[\"pixel_values\"], label_cols=[\"labels\"], shuffle=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7936e0-1679-40f0-966b-fbe23e65d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2D(filters=32, kernel_size=3, activation='relu')\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.pool1 = MaxPooling2D(pool_size=(2, 2))\n",
    "        \n",
    "        self.conv2 = Conv2D(filters=64, kernel_size=3, activation='relu')\n",
    "        self.bn2 = BatchNormalization()\n",
    "        self.pool2 = MaxPooling2D(pool_size=(2, 2))\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        self.d1 = Dense(256, activation='relu', kernel_regularizer='l2')\n",
    "        self.bn3 = BatchNormalization()\n",
    "        self.d2 = Dense(64, activation='relu', kernel_regularizer='l2')\n",
    "        self.bn4 = BatchNormalization()\n",
    "        self.d3 = Dropout(0.5)\n",
    "        self.d4 = Dense(7, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.d2(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.d3(x)\n",
    "        return self.d4(x)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310856d5-26c9-46c7-ad1b-4af2abba9a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n",
    "valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f556951-d5d6-4b4b-8b95-ce68e3336ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "\n",
    "@tf.function\n",
    "def valid_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images, training=True)\n",
    "        v_loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(v_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    valid_loss(v_loss)\n",
    "    valid_accuracy(labels, predictions)\n",
    "\n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    predictions = model(images, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dd31b3-1904-4200-b0ca-238ece0b66bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss.reset_state()\n",
    "    train_accuracy.reset_state()\n",
    "    valid_loss.reset_state()\n",
    "    valid_accuracy.reset_state()\n",
    "    test_loss.reset_state()\n",
    "    test_accuracy.reset_state()\n",
    "\n",
    "    for images, labels in train_ds:\n",
    "        train_step(images, labels)\n",
    "\n",
    "    for valid_images, valid_labels in valid_ds:\n",
    "        valid_step(valid_images, valid_labels)\n",
    "\n",
    "    for test_images, test_labels in test_ds:\n",
    "        test_step(test_images, test_labels)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, '\n",
    "          f'Loss: {train_loss.result():.2f}, '\n",
    "          f'Accuracy: {train_accuracy.result() * 100:.2f}%, '\n",
    "          f'Validation Loss: {valid_loss.result():.2f}, '\n",
    "          f'Validation Accuracy: {valid_accuracy.result() * 100:.2f}%, '\n",
    "          f'Test Loss: {test_loss.result():.2f}, '\n",
    "          f'Test Accuracy: {test_accuracy.result() * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a958da58",
   "metadata": {},
   "source": [
    "Best: 99.14"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
